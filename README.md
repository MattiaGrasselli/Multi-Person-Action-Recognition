# Multi-Person-Action-Recognition
This repository contains the Computer Vision and Cognitive Systems exam project.

# Abstract

# Code

# Demo

# What I have done and where I can try to help you
During this project I have worked on many parts:
&bull; Tracking
&bull; Designed (following the paper), written, trained all the components of the Action Recognition Network
&bull; Adapted the HMDB51 Dataset for our task
&bull; Written all the code that combines the detector (Yolov7), tracker (DeepSORT) and the Action Recognition Network

# References
[1] Matteo Fabbri, Guillem Brasó, Gianluca Maugeri, Orcun Cetintas, Riccardo Gasparini, Aljoša Ošep, Simone Calderara, Laura Leal-Taixé, Rita Cucchiara - MOTSynth: How Can Synthetic Data Help Pedestrian Detection and Tracking?
[2] Nicolai Wojke, Alex Bewley, Dietrich Paulus – Simple online and realtime tracking with a deep association metric. 
[3] Karen Simonyan, Andrew Zisserman - Two-Stream Convolutional Networks for Action Recognition in Videos
[4] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, T. Serre - HMDB: A Large Video Database for Human Motion Recognition
[5] Nicolai Wojke, AlexBewley, Dietrich Paulus - DeepSORT - https://github.com/nwojke/deep_sort
[6] Christoph Feichtenhofer, Axel Pinz, Andrew Zisserman - Convolutional Two-Stream Network Fusion for Video Action Recognition
[7] Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri - Learning Spatiotemporal Features with 3D Convolutional Networks
[8] Zhaofan Qiu, Ting Yao, Tao Mei - Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks
[9] Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, Luc Van Gool - Temporal Segment Networks for Action Recognition in Videos
[10] Fabbri, M., Lanzi, F., Gasparini, R., Calderara, S., Baraldi, L., & Cucchiara, R. (2020). Inter-homines: Distance-based risk estimation for human safety. arXiv preprint arXiv:2007.10243.

# Acknowledgments
I want to personally thank my University that gave me access to their GPUs to train the networks and I want to thank you all the people that have been working/will work on this subject. 
